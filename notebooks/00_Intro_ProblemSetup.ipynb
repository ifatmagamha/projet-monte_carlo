{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Monte Carlo Scheduling — 00: Intro & Problem Setup\n",
        "\n",
        "**Projet :** Optimisation d’ordonnancement (Scheduling) par méthodes de Monte Carlo  \n",
        "**Objectif :** développer un prototype capable de générer, simuler, évaluer et améliorer des plannings pour un ensemble de tâches sur plusieurs ressources, afin de minimiser le temps total de production et, optionnellement, les retards et d’autres critères.\n",
        "\n",
        "> Ce notebook introduit le problème, la modélisation, les métriques et la logique Monte Carlo.\n"
      ],
      "metadata": {
        "id": "mbP9VmJmOhWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan du projet et organisation\n",
        "\n",
        "Le dépôt est structuré en notebooks progressifs :\n",
        "\n",
        "- **00** — Intro, modélisation, métriques, vue d’ensemble des méthodes Monte Carlo\n",
        "- **01** — Génération d’instances (données synthétiques réalistes) + export\n",
        "- **02** — Simulateur + calcul de métriques (makespan, tardiness, score)\n",
        "- **03** — Baselines / heuristiques classiques (références)\n",
        "- **04** — Monte Carlo Random Search (échantillonnage massif)\n",
        "- **05** — Monte Carlo amélioré : Recuit simulé (Simulated Annealing)\n",
        "- **06** — Expériences & comparaison reproductibles\n",
        "- **07** — Démo finale (pipeline complet + figures)\n",
        "\n",
        "Le code réutilisable sera placé dans `src/` et les données dans `data/`.\n"
      ],
      "metadata": {
        "id": "EkTNAASwOpH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Problème d’ordonnancement (Scheduling)\n",
        "\n",
        "On considère :\n",
        "\n",
        "- un ensemble de tâches (jobs) : \\(J = \\{0,1,\\dots,n-1\\}\\)\n",
        "- un ensemble de machines / ressources : \\(M = \\{0,1,\\dots,m-1\\}\\)\n",
        "\n",
        "Chaque tâche doit être exécutée **une seule fois** sur **une seule machine**.  \n",
        "Chaque machine exécute au plus **une tâche à la fois**.\n",
        "\n",
        "Nous retenons le cas **machines parallèles non identiques** (dit “unrelated parallel machines”) :\n",
        "- temps de traitement \\(p_{j,k}\\) = durée de la tâche \\(j\\) sur la machine \\(k\\)\n",
        "\n",
        "Ce modèle est général : le cas “machines identiques” est un sous-cas (\\(p_{j,k} = p_j\\)).\n"
      ],
      "metadata": {
        "id": "GmyY-QrCOsBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Données et variables\n",
        "\n",
        "### Données\n",
        "- $p_{j,k} \\ge 0$ : durée de la tâche $j$ sur la machine $k$\n",
        "- (option) $d_j$ : deadline (date limite)\n",
        "- (option) $w_j$ : poids / priorité\n",
        "- (option) $r_j$ : release time (date de disponibilité)\n",
        "\n",
        "### Décisions (un planning)\n",
        "\n",
        "Un planning peut être représenté comme une famille de séquences :\n",
        "\n",
        "$$\n",
        "S = (\\pi_0, \\pi_1, \\dots, \\pi_{m-1})\n",
        "$$\n",
        "\n",
        "où $\\pi_k$ est la liste ordonnée des tâches exécutées sur la machine $k$.\n",
        "\n",
        "### Contraintes\n",
        "- chaque tâche apparaît **exactement une fois** dans l’union des $\\pi_k$\n",
        "- sur une machine, l’exécution est **séquentielle** (sans chevauchement)\n",
        "- pas de **préemption** (une tâche ne s’interrompt pas)\n"
      ],
      "metadata": {
        "id": "EkY6z531OuL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Évaluation par simulation\n",
        "\n",
        "Pour comparer deux plannings, on les **simule** afin de calculer :\n",
        "- $S_j$ : temps de début de la tâche $j$\n",
        "- $C_j$ : temps de fin de la tâche $j$\n",
        "\n",
        "Sur une machine $k$, si la séquence est :\n",
        "\n",
        "$$\n",
        "\\pi_k = (j_1, j_2, \\dots)\n",
        "$$\n",
        "\n",
        "on a typiquement :\n",
        "\n",
        "- $S_{j_1} = \\max(0, r_{j_1})$\n",
        "- $S_{j_t} = \\max(C_{j_{t-1}}, r_{j_t}) \\quad \\text{pour } t \\ge 2$\n",
        "\n",
        "et :\n",
        "\n",
        "$$\n",
        "C_{j_t} = S_{j_t} + p_{j_t,k}\n",
        "$$\n",
        "\n",
        "La simulation permet ainsi de reconstruire l’exécution complète du planning et de calculer des **métriques globales** telles que le makespan, le retard total ou le retard pondéré.\n"
      ],
      "metadata": {
        "id": "uur5kvEnPQe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Métriques d’optimisation\n",
        "\n",
        "### Makespan (objectif principal)\n",
        "\n",
        "$$\n",
        "C_{\\max} = \\max_{j \\in J} C_j\n",
        "$$\n",
        "\n",
        "Minimiser $C_{\\max}$ revient à minimiser la **durée totale de production**, c’est-à-dire le temps de fin de la dernière tâche.\n",
        "\n",
        "### Tardiness (retard) — optionnel\n",
        "\n",
        "$$\n",
        "T_j = \\max(0, C_j - d_j)\n",
        "$$\n",
        "\n",
        "À partir de cette définition, on peut considérer :\n",
        "- **Retard total** :  \n",
        "  $$\n",
        "  \\sum_j T_j\n",
        "  $$\n",
        "- **Retard pondéré** (si des priorités sont définies) :  \n",
        "  $$\n",
        "  \\sum_j w_j T_j\n",
        "  $$\n"
      ],
      "metadata": {
        "id": "IUm50EHzPmuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Fonction objectif (score unique)\n",
        "\n",
        "Pour comparer facilement des solutions dans une boucle Monte Carlo, on utilise un score scalaire :\n",
        "\n",
        "$$\n",
        "\\text{score} = \\alpha C_{\\max} + \\beta \\sum_j T_j + \\gamma \\sum_j w_j T_j\n",
        "$$\n",
        "\n",
        "- \\(\\alpha, \\beta, \\gamma\\) sont des poids choisis selon l’importance des critères.\n",
        "- Dans la suite, on prendra typiquement \\(\\alpha = 1\\) et \\(\\beta, \\gamma\\) plus petits.\n",
        "\n",
        "> Cette agrégation est standard en optimisation multi-critères lorsqu’on veut une comparaison simple entre solutions.\n"
      ],
      "metadata": {
        "id": "5uFA6aYCPqdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Pourquoi des méthodes de Monte Carlo ?\n",
        "\n",
        "L’espace des plannings possibles est **combinatoire** et croît très rapidement avec \\(n\\) et \\(m\\).  \n",
        "Le problème est généralement **NP-difficile**, ce qui rend l’optimisation exacte impraticable à grande échelle.\n",
        "\n",
        "Les méthodes de Monte Carlo consistent à :\n",
        "1. générer des solutions candidates (souvent aléatoires)\n",
        "2. les évaluer par simulation\n",
        "3. conserver/améliorer les meilleures solutions\n",
        "\n",
        "Elles sont adaptées aux problèmes où :\n",
        "- l’évaluation d’une solution est relativement simple (simulation)\n",
        "- l’espace de recherche est très grand\n",
        "- on vise de bonnes solutions approchées plutôt qu’un optimum exact\n"
      ],
      "metadata": {
        "id": "HdaeIwa3PwLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Méthodes Monte Carlo implémentées\n",
        "\n",
        "### (A) Monte Carlo Random Search (baseline Monte Carlo)\n",
        "- on échantillonne \\(K\\) plannings aléatoires\n",
        "- on garde le meilleur\n",
        "\n",
        "### (B) Monte Carlo amélioré : Recuit simulé (Simulated Annealing)\n",
        "- on part d’un planning initial\n",
        "- on applique des **mouvements locaux** (swap, move, swap inter-machines…)\n",
        "- on accepte toujours les améliorations\n",
        "- on accepte parfois des dégradations avec une probabilité \\(\\exp(-\\Delta / T)\\) pour échapper aux minima locaux\n",
        "\n",
        "Ces deux approches permettent :\n",
        "- d’observer une **courbe de convergence**\n",
        "- de comparer à des heuristiques classiques (SPT, EDD, greedy…)\n"
      ],
      "metadata": {
        "id": "8Ee9wSv-Py1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Livrables et résultats attendus\n",
        "\n",
        "- **Code** : générateur d’instances, simulateur, baselines, algorithmes Monte Carlo\n",
        "- **Résultats** :\n",
        "  - courbes de convergence (best-so-far vs itérations)\n",
        "  - comparaison (baseline vs Monte Carlo)\n",
        "  - diagramme de Gantt du meilleur planning\n",
        "- **Rapport (2–4 pages recommandé)** :\n",
        "  - formulation du problème\n",
        "  - description des algorithmes\n",
        "  - protocole expérimental\n",
        "  - résultats et discussion\n"
      ],
      "metadata": {
        "id": "ktQ57E4WP1hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Roadmap (prochaine étape)\n",
        "\n",
        "Dans le prochain notebook (**01_Instance_Generation**), on va :\n",
        "- définir un générateur d’instances réaliste (\\(p_{j,k}\\), deadlines…)\n",
        "- sauvegarder les instances dans `data/instances/` (format JSON)\n",
        "- assurer la reproductibilité (seed)\n",
        "\n",
        "Ensuite (**02_Simulator_and_Metrics**) :\n",
        "- on valide la simulation sur un mini-exemple\n",
        "- on calcule les métriques et le score\n"
      ],
      "metadata": {
        "id": "bvkYNkl6P5gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Reo43UgQjxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}